{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe1242b5-ce71-427d-970d-e5849105790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer   # for enabling the use of iterative imputer ( experimental module )\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea8cdaba-88d2-41e6-8ffb-5770e03455e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "filepath = \".../titanic/\"\n",
    "real_vaues = pd.read_csv(filepath + \"results.csv\", index_col='PassengerId')\n",
    "\n",
    "train_data = pd.read_csv(filepath + \"train.csv\", index_col='PassengerId') #, index_col='PassengerId'\n",
    "train_data['Sex']=train_data['Sex']=='female'\n",
    "\n",
    "test_data = pd.read_csv(filepath + \"test.csv\", index_col='PassengerId') #, index_col='PassengerId'\n",
    "test_data['Sex']=test_data['Sex']=='female'\n",
    "\n",
    "FEATURES=['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Cabin_letter', 'Title']\n",
    "\n",
    "tt_data = train_data.drop(columns=['Survived']).append(test_data)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "530d6a10-67cc-45f8-b089-19b8072cf534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 21) (1309, 21)\n",
      "(891, 11) (418, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\movse\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\movse\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "import re\n",
    "\n",
    "tt_data['Title'] = tt_data['Name'].astype(str).map(lambda x: re.split(', |\\. ', x)[1])\n",
    "tt_data.Title[~tt_data.Title.isin(['Mr','Miss','Mrs','Master'])]='other'\n",
    "\n",
    "tt_data['Cabin_letter'] = tt_data['Cabin'].astype(str).str[0]\n",
    "\n",
    "tt_data['Ticket_Frequency'] = tt_data.groupby('Ticket')['Ticket'].transform('count')\n",
    "tt_data['Ticket_Frequency'][tt_data['Ticket_Frequency']>=5] = 5\n",
    "\n",
    "tt_data['Family_size'] = tt_data['SibSp'] + tt_data['Parch']\n",
    "tt_data['Family_size'] = tt_data['Family_size'].map(lambda x: 1 if x==0 else (2 if x<5 else 3))\n",
    "\n",
    "tt_encoded = enc.fit_transform(tt_data[['Title', 'Cabin_letter', 'Embarked', 'Pclass']]).toarray()\n",
    "df_tt_encoded = pd.DataFrame(data = tt_encoded, index = tt_data.index)\n",
    "\n",
    "print(df_tt_encoded.shape, df_tt_encoded.shape)\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ecafdb66-781d-40bb-86a1-5f31c2e57b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 24) (418, 24) (1309, 24)\n"
     ]
    }
   ],
   "source": [
    "tt_full = df_tt_encoded.join(tt_data[['Sex', 'Age', 'Fare']]) #, 'Ticket_Frequency', 'Family_size'\n",
    "train_full = tt_full.loc[train_data.index]\n",
    "test_full = tt_full.loc[test_data.index]\n",
    "\n",
    "\n",
    "print(train_full.shape, test_full.shape, tt_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1e4bf1ba-22f1-408c-8af6-40fafdc9320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "it_imputer = IterativeImputer(max_iter=10, initial_strategy = 'median')\n",
    "tt_iter = pd.DataFrame(data = it_imputer.fit_transform(tt_full), columns = tt_full.columns, index = tt_full.index)\n",
    "\n",
    "\n",
    "train_iter = tt_iter.loc[train_data.index]\n",
    "test_iter = tt_iter.loc[test_data.index]\n",
    "#print(train_iter.isnull().sum(), test_iter.isnull().sum(), tt_full.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476e8967-6963-47ee-8f3a-e10705586bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1750 out of 1750 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1750 out of 1750 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "end_model = RandomForestClassifier(criterion='gini',\n",
    "                                   n_estimators=1750,\n",
    "                                   max_depth=7,\n",
    "                                   min_samples_split=6,\n",
    "                                   min_samples_leaf=6,\n",
    "                                   max_features='auto',\n",
    "                                   #bootstrap=True, same result\n",
    "                                   oob_score=True,\n",
    "                                   random_state=0,\n",
    "                                   n_jobs=-1,\n",
    "                                   verbose=1)\n",
    "\n",
    "end_model.fit(train_iter, train_data['Survived'])\n",
    "\n",
    "ans_val = (end_model.predict(test_iter)>0.5) * 1\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6224c995-e35d-4614-9ff0-004686da69f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans =  78.4688995215311 %\n"
     ]
    }
   ],
   "source": [
    "answer_pd=pd.DataFrame({'Survived':ans_val}, index = test_data.index)\n",
    "\n",
    "#answer_pd.to_csv(filepath + 'solution_V5_6.csv')\n",
    "print('ans = ', (answer_pd==real_vaues)['Survived'].sum()*100/test_data.shape[0], '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bc6f6e-6ecf-429a-b5af-09d91f5a5f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "55f11c61-3cde-4a9c-9afe-6fa9a5bb057e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 891 samples\n",
      "Epoch 1/120\n",
      "891/891 [==============================] - 0s 237us/sample - loss: 0.8133\n",
      "Epoch 2/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.7110\n",
      "Epoch 3/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.6391\n",
      "Epoch 4/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.5873\n",
      "Epoch 5/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.5467\n",
      "Epoch 6/120\n",
      "891/891 [==============================] - 0s 40us/sample - loss: 0.5169\n",
      "Epoch 7/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4956\n",
      "Epoch 8/120\n",
      "891/891 [==============================] - 0s 40us/sample - loss: 0.4796\n",
      "Epoch 9/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4682\n",
      "Epoch 10/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4596\n",
      "Epoch 11/120\n",
      "891/891 [==============================] - 0s 40us/sample - loss: 0.4533\n",
      "Epoch 12/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4484\n",
      "Epoch 13/120\n",
      "891/891 [==============================] - 0s 40us/sample - loss: 0.4445\n",
      "Epoch 14/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4417\n",
      "Epoch 15/120\n",
      "891/891 [==============================] - 0s 43us/sample - loss: 0.4389\n",
      "Epoch 16/120\n",
      "891/891 [==============================] - 0s 43us/sample - loss: 0.4369\n",
      "Epoch 17/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4353\n",
      "Epoch 18/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4336\n",
      "Epoch 19/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4327\n",
      "Epoch 20/120\n",
      "891/891 [==============================] - 0s 43us/sample - loss: 0.4313\n",
      "Epoch 21/120\n",
      "891/891 [==============================] - 0s 43us/sample - loss: 0.4301\n",
      "Epoch 22/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4291\n",
      "Epoch 23/120\n",
      "891/891 [==============================] - 0s 43us/sample - loss: 0.4287\n",
      "Epoch 24/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4281\n",
      "Epoch 25/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4276\n",
      "Epoch 26/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4269\n",
      "Epoch 27/120\n",
      "891/891 [==============================] - 0s 40us/sample - loss: 0.4263\n",
      "Epoch 28/120\n",
      "891/891 [==============================] - 0s 40us/sample - loss: 0.4268\n",
      "Epoch 29/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4257\n",
      "Epoch 30/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4257\n",
      "Epoch 31/120\n",
      "891/891 [==============================] - 0s 43us/sample - loss: 0.4249\n",
      "Epoch 32/120\n",
      "891/891 [==============================] - 0s 43us/sample - loss: 0.4254\n",
      "Epoch 33/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4247\n",
      "Epoch 34/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4248\n",
      "Epoch 35/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4245\n",
      "Epoch 36/120\n",
      "891/891 [==============================] - 0s 43us/sample - loss: 0.4247\n",
      "Epoch 37/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4245\n",
      "Epoch 38/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4242\n",
      "Epoch 39/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4243\n",
      "Epoch 40/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4239\n",
      "Epoch 41/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4240\n",
      "Epoch 42/120\n",
      "891/891 [==============================] - 0s 43us/sample - loss: 0.4241\n",
      "Epoch 43/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4237\n",
      "Epoch 44/120\n",
      "891/891 [==============================] - 0s 49us/sample - loss: 0.4238\n",
      "Epoch 45/120\n",
      "891/891 [==============================] - 0s 40us/sample - loss: 0.4238\n",
      "Epoch 46/120\n",
      "891/891 [==============================] - 0s 40us/sample - loss: 0.4243\n",
      "Epoch 47/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4236\n",
      "Epoch 48/120\n",
      "891/891 [==============================] - 0s 43us/sample - loss: 0.4242\n",
      "Epoch 49/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4235\n",
      "Epoch 50/120\n",
      "891/891 [==============================] - 0s 43us/sample - loss: 0.4240\n",
      "Epoch 51/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4246\n",
      "Epoch 52/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4240\n",
      "Epoch 53/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4238\n",
      "Epoch 54/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4238\n",
      "Epoch 55/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4235\n",
      "Epoch 56/120\n",
      "891/891 [==============================] - 0s 40us/sample - loss: 0.4237\n",
      "Epoch 57/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4234\n",
      "Epoch 58/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4237\n",
      "Epoch 59/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4237\n",
      "Epoch 60/120\n",
      "891/891 [==============================] - 0s 43us/sample - loss: 0.4234\n",
      "Epoch 61/120\n",
      "891/891 [==============================] - 0s 43us/sample - loss: 0.4239\n",
      "Epoch 62/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4239\n",
      "Epoch 63/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4232\n",
      "Epoch 64/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4235\n",
      "Epoch 65/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4242\n",
      "Epoch 66/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4237\n",
      "Epoch 67/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4234\n",
      "Epoch 68/120\n",
      "891/891 [==============================] - 0s 40us/sample - loss: 0.4237\n",
      "Epoch 69/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4237\n",
      "Epoch 70/120\n",
      "891/891 [==============================] - 0s 43us/sample - loss: 0.4232\n",
      "Epoch 71/120\n",
      "891/891 [==============================] - 0s 43us/sample - loss: 0.4234\n",
      "Epoch 72/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4242\n",
      "Epoch 73/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4236\n",
      "Epoch 74/120\n",
      "891/891 [==============================] - 0s 40us/sample - loss: 0.4231\n",
      "Epoch 75/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4235\n",
      "Epoch 76/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4233\n",
      "Epoch 77/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4238\n",
      "Epoch 78/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4245\n",
      "Epoch 79/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4237\n",
      "Epoch 80/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4236\n",
      "Epoch 81/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4233\n",
      "Epoch 82/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4232\n",
      "Epoch 83/120\n",
      "891/891 [==============================] - 0s 40us/sample - loss: 0.4238\n",
      "Epoch 84/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4232\n",
      "Epoch 85/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4244\n",
      "Epoch 86/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4243\n",
      "Epoch 87/120\n",
      "891/891 [==============================] - 0s 48us/sample - loss: 0.4237\n",
      "Epoch 88/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4234\n",
      "Epoch 89/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4233\n",
      "Epoch 90/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4233\n",
      "Epoch 91/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4233\n",
      "Epoch 92/120\n",
      "891/891 [==============================] - 0s 40us/sample - loss: 0.4236\n",
      "Epoch 93/120\n",
      "891/891 [==============================] - 0s 40us/sample - loss: 0.4237\n",
      "Epoch 94/120\n",
      "891/891 [==============================] - 0s 40us/sample - loss: 0.4232\n",
      "Epoch 95/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4238\n",
      "Epoch 96/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4230\n",
      "Epoch 97/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4245\n",
      "Epoch 98/120\n",
      "891/891 [==============================] - 0s 43us/sample - loss: 0.4237\n",
      "Epoch 99/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4230\n",
      "Epoch 100/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4237\n",
      "Epoch 101/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4227\n",
      "Epoch 102/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4232\n",
      "Epoch 103/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4234\n",
      "Epoch 104/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4229\n",
      "Epoch 105/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4231\n",
      "Epoch 106/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4236\n",
      "Epoch 107/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4246\n",
      "Epoch 108/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4230\n",
      "Epoch 109/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4233\n",
      "Epoch 110/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4231\n",
      "Epoch 111/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4230\n",
      "Epoch 112/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4231\n",
      "Epoch 113/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4235\n",
      "Epoch 114/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4229\n",
      "Epoch 115/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4230\n",
      "Epoch 116/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4234\n",
      "Epoch 117/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4238\n",
      "Epoch 118/120\n",
      "891/891 [==============================] - 0s 42us/sample - loss: 0.4233\n",
      "Epoch 119/120\n",
      "891/891 [==============================] - 0s 40us/sample - loss: 0.4242\n",
      "Epoch 120/120\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.4233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x227ff86f808>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "features_nn = [ 'Age',  'Fare']\n",
    "scaler.fit(tt_iter[features_nn])\n",
    "df=pd.DataFrame(data = scaler.transform(train_iter[features_nn]), columns = features_nn, index = train_iter.index)\n",
    "df1 = (train_iter.drop(columns = features_nn)-0.1).join(df)\n",
    "df3=pd.DataFrame(data = scaler.transform(test_iter[features_nn]), columns = features_nn, index = test_iter.index)\n",
    "df4 = (test_iter.drop(columns = features_nn)-0.1).join(df3)\n",
    "\n",
    "\n",
    "end_nn_model = Sequential()\n",
    "end_nn_model.add(Dense(10, input_shape = [df1.shape[1]], bias_initializer=tf.random.normal ))    # you could write imput_dim = ..., <-(in new versions) activation = 'relu' etc.\n",
    "#end_nn_model.add(Dense(15, bias_initializer=tf.random.normal))\n",
    "end_nn_model.add(Dense(1)) #output\n",
    "\n",
    "end_nn_model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True))\n",
    "\n",
    "end_nn_model.fit(df1, train_data['Survived'], verbose=1, epochs = 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1d8c1ba6-3ca3-4a88-a77e-255f0516c424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans =  80.14354066985646 %\n"
     ]
    }
   ],
   "source": [
    "answers = end_nn_model.predict(df4)>0.5\n",
    "answers = answers*1   # true false to 1 and 0 \n",
    "answers = answers.reshape(answers.shape[0])\n",
    "answer_pd = pd.DataFrame( {'Survived' : answers}, index = test_data.index)\n",
    "answer_pd.to_csv(filepath + 'solution_V6_nn_1.csv')\n",
    "print('ans = ', (answer_pd==real_vaues)['Survived'].sum()*100/test_data.shape[0], '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d78e2222-8057-4bf2-9e40-ae74ebce3d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans =  83.05274971941638 %\n"
     ]
    }
   ],
   "source": [
    "answers = end_nn_model.predict(df1)>0.5\n",
    "answers = answers*1   # true false to 1 and 0 \n",
    "answers = answers.reshape(answers.shape[0])\n",
    "answer_pd = pd.DataFrame( {'Survived' : answers}, index = train_data.index)\n",
    "#answer_pd.to_csv(filepath + 'solution_V6_nn_OHE.csv')\n",
    "print('ans = ', (answer_pd==pd.DataFrame(train_data.Survived))['Survived'].sum()*100/train_data.shape[0], '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ca8890-f5c2-4acc-bb54-f877d9e6ea7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9e083615-e00e-4723-ba48-fe99fbfc8357",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tt_data['Family_size'] = tt_data['SibSp'] + tt_data['Parch']\n",
    "tt_data['Family_size'] = tt_data['Family_size'].map(lambda x: 1 if x==0 else (2 if x<5 else 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7eb224-433f-4424-909f-4711978972d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    790\n",
       "2    459\n",
       "3     60\n",
       "Name: Family_size, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_data.Family_size.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a060216-965b-42f2-af8a-fb0fa84ceeee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
